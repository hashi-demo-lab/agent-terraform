# Terraform Code Generation Agent - Cursor Rules

## Project Structure and Standards

### Directory Architecture
Follow this exact structure for all Terraform agent development:

```
terraform-agent/
├── src/
│   ├── agents/
│   │   ├── planner.py          # Requirements analysis and resource planning (LangGraph node)
│   │   ├── generator.py        # Code generation and templating (LangGraph node)
│   │   ├── validator.py        # Multi-tool validation orchestration (LangGraph node)
│   │   ├── refiner.py          # Code improvement and optimization (LangGraph node)
│   │   ├── documenter.py       # Documentation generation (LangGraph node)
│   │   └── reviewer.py         # Final quality assurance (LangGraph node)
│   ├── workflows/
│   │   ├── terraform_workflow.py  # Main LangGraph Platform workflow
│   │   ├── state_management.py    # LangGraph state definitions and management
│   │   └── workflow_manager.py    # LangGraph Platform workflow execution
│   ├── tools/
│   │   ├── terraform_tools.py     # Terraform CLI wrappers (LangGraph ToolNode)
│   │   ├── tflint_tools.py        # TFLint integration (AVM ruleset, LangGraph ToolNode)
│   │   └── trivy_tools.py         # Trivy security scanning (LangGraph ToolNode)
│   ├── templates/
│   │   ├── aws/                   # AWS-specific templates
│   │   ├── azure/                 # Azure-specific templates
│   │   ├── gcp/                   # GCP-specific templates
│   │   └── base/                  # Base module templates
│   ├── platform/
│   │   ├── langgraph_config.py    # LangGraph Platform configuration
│   │   ├── checkpointers.py       # State persistence and checkpointing
│   │   └── deployment.py          # LangGraph Platform deployment configuration
│   ├── config/
│   │   ├── validation_rules.yaml  # Validation tool configurations
│   │   ├── best_practices.yaml    # Best practice enforcement
│   │   ├── cloud_configs.yaml     # Cloud provider settings
│   │   └── langgraph.yaml         # LangGraph Platform configuration
│   └── utils/
│       ├── terraform_parser.py    # HCL parsing utilities
│       ├── file_manager.py        # File system operations
│       └── cli_integration.py     # Claude Coder/OpenCode-AI integration
├── tests/
│   ├── unit/
│   ├── integration/
│   └── terraform/                 # Terraform test configurations
├── examples/
│   ├── generated_modules/         # Example generated modules
│   └── workflows/                 # Example workflow configurations
├── docs/
│   ├── architecture.md
│   ├── api_reference.md
│   └── user_guide.md
├── config/
│   ├── development.yaml
│   ├── production.yaml
│   └── local.yaml
└── scripts/
    ├── setup.sh
    ├── validate.sh
    └── deploy.sh
```

## Coding Standards

### Python Development Rules

**MANDATORY**: All development MUST use LangGraph Platform for workflow orchestration, state management, and agent coordination.

1. **LangGraph Platform Integration**:
   ```python
   # MANDATORY: Use LangGraph Platform for all workflow management
   from langgraph import StateGraph, START, END, MessagesState
   from langgraph.platform import LangGraphPlatform
   from langgraph.checkpoint.memory import MemorySaver
   from langgraph.prebuilt import ToolNode
   
   # Initialize LangGraph Platform
   platform = LangGraphPlatform()
   checkpointer = MemorySaver()
   ```

2. **Agent Implementation with LangGraph Platform**:
   ```python
   # Each agent must be implemented as LangGraph nodes
   from langgraph import StateGraph
   from typing import TypedDict, Annotated
   from langchain_core.messages import BaseMessage
   
   class TerraformState(TypedDict):
       messages: Annotated[list[BaseMessage], "The messages in the conversation"]
       requirements: dict
       generated_code: str
       validation_results: list
       iteration_count: int
       current_agent: str
   
   class PlannerAgent:
       def __init__(self, platform: LangGraphPlatform):
           self.platform = platform
           self.max_iterations = 5
       
       def __call__(self, state: TerraformState) -> TerraformState:
           # Agent logic here
           return state
   ```

3. **Workflow Definition with LangGraph Platform**:
   ```python
   # MANDATORY: Use LangGraph Platform for workflow orchestration
   def create_terraform_workflow() -> StateGraph:
       workflow = StateGraph(TerraformState)
       
       # Add agent nodes
       workflow.add_node("planner", PlannerAgent(platform))
       workflow.add_node("generator", GeneratorAgent(platform))
       workflow.add_node("validator", ValidatorAgent(platform))
       workflow.add_node("refiner", RefinerAgent(platform))
       workflow.add_node("documenter", DocumenterAgent(platform))
       workflow.add_node("reviewer", ReviewerAgent(platform))
       
       # Add tool nodes for validation
       workflow.add_node("terraform_tools", ToolNode([terraform_validate, terraform_fmt]))
       workflow.add_node("tflint_tools", ToolNode([tflint_avm_validate]))
       workflow.add_node("trivy_tools", ToolNode([trivy_scan]))
       
       # Define workflow edges
       workflow.add_edge(START, "planner")
       workflow.add_edge("planner", "generator")
       workflow.add_edge("generator", "validator")
       workflow.add_conditional_edges(
           "validator",
           should_continue_validation,
           {
               "continue": "refiner",
               "complete": "documenter"
           }
       )
       workflow.add_edge("refiner", "generator")
       workflow.add_edge("documenter", "reviewer")
       workflow.add_edge("reviewer", END)
       
       return workflow.compile(checkpointer=checkpointer)
   ```

4. **State Management with LangGraph Platform**:
   ```python
   # MANDATORY: Use LangGraph Platform state management
   from langgraph.checkpoint import BaseCheckpointSaver
   
   class TerraformWorkflowManager:
       def __init__(self):
           self.platform = LangGraphPlatform()
           self.workflow = create_terraform_workflow()
           
       async def execute_workflow(self, requirements: dict, thread_id: str):
           config = {"configurable": {"thread_id": thread_id}}
           
           initial_state = {
               "messages": [],
               "requirements": requirements,
               "generated_code": "",
               "validation_results": [],
               "iteration_count": 0,
               "current_agent": "planner"
           }
           
           async for event in self.workflow.astream(initial_state, config):
               yield event
   ```

### Terraform Code Generation Rules

1. **Module Structure Enforcement**:
   - Always generate following [hashi-demo-lab/tf-module-template](https://github.com/hashi-demo-lab/tf-module-template) structure
   - Use standard file organization: main.tf, variables.tf, outputs.tf, providers.tf, versions.tf, locals.tf
   - Include comprehensive variable validation
   - Provide detailed descriptions for all variables and outputs
   - Implement proper resource tagging
   - Follow HashiCorp's [Standard Module Structure](https://developer.hashicorp.com/terraform/language/modules/develop/structure)
   - Apply [Azure Verified Modules](https://azure.github.io/Azure-Verified-Modules/specs/tf/) best practices for generic module development

2. **Security-First Approach**:
   ```hcl
   # Always include security best practices following AWS provider specifications
   resource "aws_s3_bucket_public_access_block" "example" {
     bucket = aws_s3_bucket.example.id
     
     block_public_acls       = true
     block_public_policy     = true
     ignore_public_acls      = true
     restrict_public_buckets = true
   }
   
   # Use latest AWS provider resource configurations
   resource "aws_s3_bucket_server_side_encryption_configuration" "example" {
     bucket = aws_s3_bucket.example.id
     
     rule {
       apply_server_side_encryption_by_default {
         sse_algorithm = "AES256"
       }
     }
   }
   ```

3. **Variable Standards**:
   ```hcl
   variable "environment" {
     description = "Environment name (e.g., dev, staging, prod)"
     type        = string
     validation {
       condition     = contains(["dev", "staging", "prod"], var.environment)
       error_message = "Environment must be dev, staging, or prod."
     }
   }
   ```

### Validation Pipeline Rules

**MANDATORY**: All validation must be orchestrated through LangGraph Platform workflows with proper state management and tool integration.

1. **LangGraph Platform Validation Workflow**:
   ```python
   # MANDATORY: Use LangGraph Platform for validation orchestration
   from langgraph.prebuilt import ToolNode
   from langgraph import StateGraph
   
   def create_validation_workflow() -> StateGraph:
       workflow = StateGraph(TerraformState)
       
       # Add validation tool nodes
       terraform_tools = ToolNode([
           terraform_validate_tool,
           terraform_fmt_tool,
           terraform_test_tool
       ])
       
       tflint_tools = ToolNode([tflint_avm_validate_tool])
       trivy_tools = ToolNode([trivy_scan_tool])
       
       workflow.add_node("terraform_validation", terraform_tools)
       workflow.add_node("tflint_validation", tflint_tools)
       workflow.add_node("trivy_validation", trivy_tools)
       workflow.add_node("validation_aggregator", aggregate_validation_results)
       
       # Define validation flow
       workflow.add_edge(START, "terraform_validation")
       workflow.add_edge("terraform_validation", "tflint_validation")
       workflow.add_edge("tflint_validation", "trivy_validation")
       workflow.add_edge("trivy_validation", "validation_aggregator")
       
       return workflow.compile(checkpointer=checkpointer)
   ```

2. **Cyclical Validation with LangGraph Platform**:
   ```python
   # MANDATORY: Implement cyclical validation using LangGraph Platform state management
   async def validate_terraform_code_workflow(
       initial_state: TerraformState, 
       max_iterations: int = 5
   ) -> TerraformState:
       
       validation_workflow = create_validation_workflow()
       config = {"configurable": {"thread_id": f"validation_{uuid.uuid4()}"}}
       
       current_state = initial_state
       
       for iteration in range(max_iterations):
           # Run validation workflow
           async for event in validation_workflow.astream(current_state, config):
               if "validation_aggregator" in event:
                   current_state = event["validation_aggregator"]
           
           # Check if validation passed
           if all(result.passed for result in current_state["validation_results"]):
               break
               
           # If validation failed, trigger refinement workflow
           current_state["iteration_count"] = iteration + 1
           refinement_workflow = create_refinement_workflow()
           
           async for event in refinement_workflow.astream(current_state, config):
               if "refiner" in event:
                   current_state = event["refiner"]
       
       return current_state
   ```

3. **Tool Integration with LangGraph Platform**:
   ```python
   # MANDATORY: All validation tools must be implemented as LangGraph tools
   from langchain_core.tools import tool
   from langgraph.prebuilt import ToolNode
   
   @tool
   def terraform_validate_tool(code: str) -> dict:
       """Validate Terraform code syntax and configuration."""
       # Implementation here
       return {"tool": "terraform_validate", "passed": True, "messages": []}
   
   @tool
   def tflint_avm_validate_tool(code: str) -> dict:
       """Validate Terraform code against Azure Verified Modules ruleset."""
       # Implementation here
       return {"tool": "tflint_avm", "passed": True, "messages": []}
   
   @tool
   def trivy_scan_tool(code: str) -> dict:
       """Scan Terraform code for security vulnerabilities."""
       # Implementation here
       return {"tool": "trivy", "passed": True, "messages": []}
   
   # Tool execution order in LangGraph Platform
   VALIDATION_TOOL_SEQUENCE = [
       terraform_validate_tool,
       terraform_fmt_tool,
       terraform_test_tool,
       tflint_avm_validate_tool,
       trivy_scan_tool
   ]
   ```

### CLI Integration Rules

1. **Claude Coder Integration**:
   ```python
   # Implement language server protocol support
   from lsp_server import LanguageServer
   
   class TerraformLanguageServer(LanguageServer):
       def __init__(self):
           super().__init__()
           self.agent_client = TerraformAgentClient()
   ```

2. **Command Line Interface**:
   ```python
   # Use Click for CLI implementation
   import click
   
   @click.group()
   def terraform_agent():
       """Terraform Code Generation Agent CLI"""
       pass
   
   @terraform_agent.command()
   @click.option('--requirements', '-r', help='Requirements file path')
   def generate(requirements):
       """Generate Terraform module from requirements"""
       pass
   ```

### MCP Integration Rules

1. **Terraform Registry Integration**:
   - Use [HashiCorp Terraform MCP Server](https://github.com/hashicorp/terraform-mcp-server) for Terraform Registry API integration
   - Implement provider and module discovery automation
   - Extract and analyze data from Terraform Registry
   - Get detailed information about provider resources and data sources

2. **AWS Provider Focus**:
   - Primary focus on [HashiCorp Terraform AWS Provider](https://github.com/hashicorp/terraform-provider-aws)
   - Reference AWS provider specifications and resource definitions
   - Use AWS provider documentation for accurate resource configurations
   - Leverage AWS provider examples and best practices

3. **MCP Tool Configuration**:
   ```json
   {
     "mcp": {
       "servers": {
         "terraform": {
           "command": "docker",
           "args": [
             "run",
             "-i",
             "--rm",
             "hashicorp/terraform-mcp-server"
           ]
         }
       }
     }
   }
   ```

4. **Available MCP Toolsets**:
   ```python
   MCP_TOOLS = {
       "providers": {
           "resolveProviderDocID": "Find available documentation for specific provider",
           "getProviderDocs": "Fetch complete documentation content for provider resources"
       },
       "modules": {
           "searchModules": "Search Terraform Registry for modules with pagination",
           "moduleDetails": "Retrieve detailed module documentation and examples"
       }
   }
   ```

5. **MCP Integration Implementation**:
   ```python
   # Integrate MCP tools for Terraform Registry access
   from mcp_client import MCPClient
   
   class TerraformMCPIntegration:
       def __init__(self):
           self.mcp_client = MCPClient("terraform")
       
       async def search_providers(self, provider_name: str):
           return await self.mcp_client.call_tool(
               "resolveProviderDocID", 
               {"serviceSlug": provider_name}
           )
       
       async def get_module_details(self, module_id: str):
           return await self.mcp_client.call_tool(
               "moduleDetails",
               {"moduleId": module_id}
           )
       
       async def get_aws_provider_docs(self, resource_type: str):
           return await self.mcp_client.call_tool(
               "getProviderDocs",
               {"serviceSlug": "aws", "resourceType": resource_type}
           )
   ```

## Configuration Management

### Environment Configuration
```yaml
# config/development.yaml
terraform:
  version: "1.12"
  backend: "local"
  
validation:
  max_iterations: 5
  fail_fast: false
  
tools:
  tflint:
    config_path: ".tflint.hcl"
    enabled_rules: ["all"]
  
  trivy:
    severity: ["HIGH", "CRITICAL"]
    scan_type: ["config", "secret"]

langgraph_platform:
  checkpointer: "memory"  # or "postgres", "redis" for production
  persistence: true
  thread_management: true
  state_schema: "TerraformState"
```

### Best Practices Configuration
```yaml
# config/best_practices.yaml
naming_conventions:
  resources: "snake_case"
  variables: "snake_case"
  outputs: "snake_case"
  
tagging:
  required_tags:
    - "Environment"
    - "Project"
    - "Owner"
    - "CostCenter"
  
security:
  encryption_at_rest: true
  encryption_in_transit: true
  public_access_blocked: true
  
documentation:
  require_descriptions: true
  include_examples: true
  generate_diagrams: true
```

## Azure Verified Modules (AVM) Best Practices

Based on [Azure Verified Modules Terraform Specifications](https://azure.github.io/Azure-Verified-Modules/specs/tf/) and detailed in [AVM_BEST_PRACTICES.md](./AVM_BEST_PRACTICES.md), implement these generic best practices:

### Code Style Standards
1. **Naming Conventions**:
   - Use snake_case for all resource names, variables, and outputs
   - Prefix variables with descriptive context (e.g., `enable_`, `create_`, `default_`)
   - Use consistent naming patterns across modules

2. **Variable Validation**:
   ```hcl
   variable "environment" {
     description = "Environment name (e.g., dev, staging, prod)"
     type        = string
     validation {
       condition     = contains(["dev", "staging", "prod"], var.environment)
       error_message = "Environment must be dev, staging, or prod."
     }
   }
   ```

3. **Output Standards**:
   ```hcl
   output "resource_id" {
     description = "The resource identifier of the created resource"
     value       = aws_resource.example.id
   }
   
   output "resource_name" {
     description = "The name of the created resource"
     value       = aws_resource.example.name
   }
   ```

### Module Classification Standards
1. **Resource Modules**: Single-purpose modules for specific resources
2. **Pattern Modules**: Multi-resource modules implementing common patterns
3. **Utility Modules**: Helper modules for common operations

### Contribution and Support Standards
1. **Module Ownership**: Clear ownership and maintenance responsibilities
2. **Issue Tracking**: Comprehensive issue tracking and resolution
3. **Community Support**: Active community engagement and support

### Telemetry Integration
1. **Usage Tracking**: Implement telemetry for module usage analytics
2. **Performance Monitoring**: Track module performance and optimization
3. **Compliance Reporting**: Generate compliance and governance reports

## Testing Standards

### Unit Testing
```python
# tests/unit/test_generator_agent.py
import pytest
from src.agents.generator import GeneratorAgent

class TestGeneratorAgent:
    @pytest.fixture
    def generator_agent(self):
        return GeneratorAgent()
    
    def test_generate_aws_module(self, generator_agent):
        requirements = {"provider": "aws", "resources": ["s3_bucket"]}
        result = generator_agent.generate_module(requirements)
        assert "resource \"aws_s3_bucket\"" in result
```

### Terraform Testing
```hcl
# tests/terraform/s3_module_test.tftest.hcl
run "validate_s3_bucket_creation" {
  command = plan
  
  variables {
    bucket_name = "test-bucket"
    environment = "dev"
  }
  
  assert {
    condition     = aws_s3_bucket.example.bucket == "test-bucket-dev"
    error_message = "Bucket name should include environment suffix"
  }
}
```

## Error Handling and Logging

### Error Handling
```python
from typing import Result
import structlog

logger = structlog.get_logger()

class TerraformAgentError(Exception):
    """Base exception for Terraform Agent"""
    pass

class ValidationError(TerraformAgentError):
    """Validation pipeline errors"""
    pass

async def safe_execute(func, *args, **kwargs) -> Result:
    try:
        result = await func(*args, **kwargs)
        logger.info("Operation completed successfully", function=func.__name__)
        return Result.success(result)
    except Exception as e:
        logger.error("Operation failed", function=func.__name__, error=str(e))
        return Result.failure(e)
```

### Structured Logging
```python
# Configure structured logging
import structlog

logger = structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.JSONRenderer()
    ],
    wrapper_class=structlog.stdlib.BoundLogger,
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
)
```

## Performance Requirements

1. **Async/Await Pattern**: Use async/await for all I/O operations
2. **Connection Pooling**: Implement connection pooling for external tool calls
3. **Caching**: Cache validation results and template generations
4. **Memory Management**: Implement proper cleanup in LangMem contexts

## Security Requirements

1. **Secret Management**: Never hardcode secrets in generated code
2. **Input Validation**: Validate all user inputs and requirements
3. **Sandboxed Execution**: Run validation tools in isolated environments
4. **Audit Logging**: Log all code generation and validation activities

## Documentation Requirements

1. **Inline Documentation**: All functions must have comprehensive docstrings
2. **Type Hints**: Use Python type hints throughout the codebase
3. **README Generation**: Auto-generate module READMEs with terraform-docs
4. **API Documentation**: Maintain OpenAPI specifications for all endpoints
5. **AVM Documentation Standards**: Follow Azure Verified Modules documentation requirements
6. **Usage Examples**: Include practical examples for all module classifications

## LangGraph Platform Deployment

**MANDATORY**: All deployments must use LangGraph Platform for production-ready workflow orchestration.

### 1. Platform Configuration
```python
# platform/langgraph_config.py
from langgraph.platform import LangGraphPlatform
from langgraph.checkpoint.postgres import PostgresCheckpointSaver
from langgraph.checkpoint.memory import MemorySaver

class PlatformConfig:
    def __init__(self, environment: str = "development"):
        self.environment = environment
        self.platform = LangGraphPlatform()
        
    def get_checkpointer(self):
        if self.environment == "production":
            return PostgresCheckpointSaver(
                connection_string=os.getenv("POSTGRES_CONNECTION_STRING")
            )
        return MemorySaver()
    
    def configure_deployment(self):
        return {
            "workflows": {
                "terraform_generation": create_terraform_workflow(),
                "validation_pipeline": create_validation_workflow(),
                "refinement_cycle": create_refinement_workflow()
            },
            "checkpointer": self.get_checkpointer(),
            "thread_management": True,
            "state_persistence": True
        }
```

### 2. Workflow Deployment
```python
# platform/deployment.py
from langgraph.platform.deployment import deploy_workflow

async def deploy_terraform_agent():
    config = PlatformConfig("production")
    deployment_config = config.configure_deployment()
    
    # Deploy to LangGraph Platform
    deployment = await deploy_workflow(
        workflow=deployment_config["workflows"]["terraform_generation"],
        name="terraform-code-generation-agent",
        version="1.0.0",
        checkpointer=deployment_config["checkpointer"]
    )
    
    return deployment
```

### 3. State Management
```yaml
# config/langgraph.yaml
platform:
  name: "terraform-agent"
  version: "1.0.0"
  
workflows:
  terraform_generation:
    state_schema: "TerraformState"
    checkpointer: "postgres"
    max_iterations: 5
    timeout: 3600
    
  validation_pipeline:
    state_schema: "ValidationState"
    checkpointer: "memory"
    timeout: 600
    
deployment:
  environment: "production"
  scaling:
    min_instances: 1
    max_instances: 10
  monitoring:
    enabled: true
    metrics: ["execution_time", "success_rate", "error_rate"]
```

## Integration Points

1. **Version Control**: Git integration for generated module versioning
2. **CI/CD**: GitHub Actions/GitLab CI integration templates
3. **Monitoring**: Prometheus metrics and Grafana dashboards
4. **Cloud Integration**: Support for Terraform Cloud/Enterprise
5. **MCP Integration**: [HashiCorp Terraform MCP Server](https://github.com/hashicorp/terraform-mcp-server) for Terraform Registry API access
6. **Registry Automation**: Automated provider and module discovery through MCP tools

## Terraform Module Template Structure

When generating new Terraform modules, always follow the [hashi-demo-lab/tf-module-template](https://github.com/hashi-demo-lab/tf-module-template) structure:

### Required Files (Root Module)
- **main.tf** - Primary resource definitions and module logic
- **variables.tf** - Input variable declarations with descriptions and validation
- **outputs.tf** - Output value definitions with descriptions
- **providers.tf** - Terraform version constraints and backend configuration
- **versions.tf** - Provider version constraints
- **locals.tf** - Local value definitions for computed values
- **terraform.auto.tfvars** - Terraform variables file

### Optional Structure Elements
- **README.md** - Module documentation (auto-generated with terraform-docs)
- **LICENSE** - Module license
- **examples/** - Usage examples directory
- **tests/** - Terraform test configurations
- **.github/** - GitHub workflows and templates
- **.pre-commit-config.yaml** - Pre-commit hooks configuration

### File Organization Standards
```hcl
# providers.tf - Backend and Terraform version
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# versions.tf - Provider configurations
provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = local.common_tags
  }
}

# variables.tf - Input variables following AWS provider patterns
variable "environment" {
  description = "Environment name (e.g., dev, staging, prod)"
  type        = string
  validation {
    condition     = contains(["dev", "staging", "prod"], var.environment)
    error_message = "Environment must be dev, staging, or prod."
  }
}

variable "aws_region" {
  description = "AWS region for resources"
  type        = string
  default     = "us-west-2"
  validation {
    condition = can(regex("^[a-z]{2}-[a-z]+-[0-9]$", var.aws_region))
    error_message = "AWS region must be in valid format (e.g., us-west-2)."
  }
}

# locals.tf - Computed values
locals {
  common_tags = {
    Environment = var.environment
    Project     = var.project_name
    ManagedBy   = "terraform"
    CreatedBy   = "terraform-agent"
  }
  
  bucket_name = "${var.project_name}-${var.environment}-${random_id.bucket_suffix.hex}"
}

# main.tf - AWS resources following provider specifications
resource "random_id" "bucket_suffix" {
  byte_length = 4
}

resource "aws_s3_bucket" "example" {
  bucket = local.bucket_name
}

resource "aws_s3_bucket_versioning" "example" {
  bucket = aws_s3_bucket.example.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "example" {
  bucket = aws_s3_bucket.example.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_public_access_block" "example" {
  bucket = aws_s3_bucket.example.id
  
  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# outputs.tf - Output values
output "bucket_name" {
  description = "Name of the created S3 bucket"
  value       = aws_s3_bucket.example.bucket
}

output "bucket_arn" {
  description = "ARN of the created S3 bucket"
  value       = aws_s3_bucket.example.arn
}
```

## Code Review Checklist

Before committing any code, ensure:
- [ ] Follows [hashi-demo-lab/tf-module-template](https://github.com/hashi-demo-lab/tf-module-template) structure
- [ ] Uses standard file organization (main.tf, variables.tf, outputs.tf, providers.tf, versions.tf, locals.tf)
- [ ] Applies [Azure Verified Modules](https://azure.github.io/Azure-Verified-Modules/specs/tf/) best practices for local copy see ./AVM_BEST_PRACTICES.md
- [ ] Implements proper module classification (Resource/Pattern/Utility)
- [ ] Integrates with [HashiCorp Terraform MCP Server](https://github.com/hashicorp/terraform-mcp-server) for registry access
- [ ] Implements MCP tools for provider and module discovery
- [ ] Passes all validation tools ("terraform validate", "terraform test", "tflint_avm", "trivy")
- [ ] Includes comprehensive unit tests, using "terraform test"
- [ ] Implements security best practices
- [ ] Generates complete documentation with terraform-docs
- [ ] Uses async/await patterns appropriately
- [ ] Includes proper type hints and docstrings
- [ ] Follows AVM naming conventions and coding standards 